

*testRELU.py* uses relu activation function for each layer
*testELU.py* uses elu activation function for each layer
*testLINEAR.py* uses linear activation function for each layer

*test_normalised.py* uses normalised data which is normalised to a value between 0 and 1

*test_feature_selection.py* uses the dataset after featuresection has been done for better accuracy.
